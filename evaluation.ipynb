{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cabfadd-ed34-4a39-a2ae-43b9537dfce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import json\n",
    "import torch\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c106d09e-6014-4d30-a732-fa6d759c9897",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f837155f-e7b2-4222-83f3-a5d73b0b24f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_device(\"cuda\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-2\", torch_dtype=\"auto\", trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-2\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a02b485-3604-48ec-8914-3eaa9876878a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prediction_from_row(row):\n",
    "    prompt = f\"{row['signature']}\\n\\\"\\\"\\\"\\n{row['docstring']}\\n\\\"\\\"\\\"\"\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", return_attention_mask=False)\n",
    "    outputs = model.generate(**inputs, max_length=1000)\n",
    "    generated_code = tokenizer.batch_decode(outputs)[0]\n",
    "\n",
    "    end_of_docstring = generated_code.find('\"\"\"') + 3\n",
    "    start_of_next_def = generated_code.find('def', end_of_docstring)\n",
    "    \n",
    "    if start_of_next_def == -1:\n",
    "        start_of_next_def = len(generated_code)\n",
    "\n",
    "    function_body = generated_code[end_of_docstring:start_of_next_def].strip()\n",
    "    function_body = function_body.replace('\\n', ' ')\n",
    "    function_body = function_body.split('\"\"\"')[-1].strip()\n",
    "    function_body = re.sub(' +', ' ', function_body)\n",
    "\n",
    "    return function_body\n",
    "\n",
    "def predictions(file_path, output_path='predictions.txt'):\n",
    "    if file_path.endswith('.csv'):\n",
    "        data = pd.read_csv(file_path)\n",
    "    elif file_path.endswith('.json'):\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        data = pd.DataFrame(data)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Please provide a .csv or .json file.\")\n",
    "\n",
    "    with open(output_path, 'w') as f:\n",
    "        i = 0\n",
    "        for index, row in data.iterrows():\n",
    "            function_body = generate_prediction_from_row(row)\n",
    "            f.write(function_body + '\\n')\n",
    "            i += 1\n",
    "            print(i)\n",
    "            if i == 100:\n",
    "                print(\"All generated codes have been written to predictions.txt\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97b252d-1fc5-41f6-bcc2-7d4869ab8ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions('./data/datasets/kotlin_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9deca12f-dcd0-4f1b-98b2-c774f743a6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions('./data/datasets/python_full.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897b4837-6443-45c7-9ab6-3b2f709e94e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "with open('predictions.txt', 'w') as f:\n",
    "    for index, row in df_python_test.iterrows():\n",
    "        prompt = f\"{row['signature']}\\n\\\"\\\"\\\"\\n{row['docstring']}\\n\\\"\\\"\\\"\"\n",
    "\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\", return_attention_mask=False)\n",
    "\n",
    "        outputs = model.generate(**inputs, max_length=1000)\n",
    "\n",
    "        generated_code = tokenizer.batch_decode(outputs)[0]\n",
    "\n",
    "        end_of_docstring = generated_code.find('\"\"\"') + 3\n",
    "\n",
    "        start_of_next_def = generated_code.find('def', end_of_docstring)\n",
    "        if start_of_next_def == -1:\n",
    "            start_of_next_def = len(generated_code)\n",
    "\n",
    "        function_body = generated_code[end_of_docstring:start_of_next_def].strip()\n",
    "\n",
    "        function_body = function_body.replace('\\n', ' ')\n",
    "        function_body = function_body.split('\"\"\"')[-1].strip()\n",
    "\n",
    "        function_body = re.sub(' +', ' ', function_body)\n",
    "        f.write(function_body + '\\n')\n",
    "        # print(function_body)\n",
    "        i += 1\n",
    "        print(i)\n",
    "        if i == 100:\n",
    "            print(\"All generated codes have been written to predictions.txt\")\n",
    "            break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fc7ac2-3c4e-448d-8265-aee4c13d9c70",
   "metadata": {
    "id": "v5uvuUYl9UAa"
   },
   "source": [
    "```\n",
    "Evaluator\n",
    "We provide a script to evaluate predictions for this task, and report accuracy score. You can run the script like this:\n",
    "\n",
    "python evaluator.py -a=evaluator/answers.txt -p=evaluator/predictions.txt\n",
    "Each line in the *.txt file is an output.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ac32b5-f5c7-4a8e-9d8c-a27b1c4c9c20",
   "metadata": {},
   "source": [
    "# Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61797d7-542a-491f-9f89-53668248fb35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
